{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix, f1_score\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_trans = pd.read_csv('transformed_wine_data/white_wine_trans.csv')\n",
    "red_wine_trans = pd.read_csv('transformed_wine_data/red_wine_trans.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression Approach </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> White wine  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_white = white_wine_trans.drop(['quality_label', 'quality', 'type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_white = white_wine_trans['quality_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train | Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_white, y_white, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Try on default settings first </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default uses L2 regularisation with C = 1.\n",
    "# multi_class = \"ovr\": do one vs rest and choose label with highest hypothesis.\n",
    "\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "log_model.fit(scaled_X_train, y_train)\n",
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319727891156463"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig, ax = plt.subplots(figsize=(5, 5))\\nplot_confusion_matrix(log_model,scaled_X_test,y_test, ax = ax)\\nplt.xticks (rotation = 90)\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot_confusion_matrix(log_model,scaled_X_test,y_test, ax = ax)\n",
    "plt.xticks (rotation = 90)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00        55\n",
      "         low       0.50      0.02      0.03        60\n",
      "lower_middle       0.57      0.57      0.57       438\n",
      "      middle       0.53      0.75      0.62       666\n",
      "upper_middle       0.37      0.12      0.18       251\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.39      0.29      0.28      1470\n",
      "weighted avg       0.49      0.53      0.48      1470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy of 53%. <br>\n",
    "Decent f1 scores for non-outlier labels. <br>\n",
    "Very poor f1 scores for outlier labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> GridSearch for Best Hyper Parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base log reg model\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Documentation  recommends logarithmic spacing. \n",
    "C = np.linspace(0.001,50,10)\n",
    "\n",
    "grid_model = GridSearchCV(log_model,param_grid={'C':C,'penalty':penalty}, scoring = 'f1_micro')\n",
    "\n",
    "# Note, f1 micro average is just regular accuracy. \n",
    "# f1 macro average is the mean of all f1 scores. \n",
    "# We won't look at weighted average for now, since we care about f1 scores for all classes equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=5000, multi_class='ovr',\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.00000000e-03, 5.55644444e+00, 1.11118889e+01, 1.66673333e+01,\n",
       "       2.22227778e+01, 2.77782222e+01, 3.33336667e+01, 3.88891111e+01,\n",
       "       4.44445556e+01, 5.00000000e+01]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run time = 15 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 16.667333333333335, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predict and Evaluate </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5312925170068027"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig, ax = plt.subplots(figsize=(5, 5))\\nplot_confusion_matrix(grid_model,scaled_X_test,y_test, ax = ax)\\nplt.xticks(rotation = 90)\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot_confusion_matrix(grid_model,scaled_X_test,y_test, ax = ax)\n",
    "plt.xticks(rotation = 90)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00        55\n",
      "         low       0.50      0.02      0.03        60\n",
      "lower_middle       0.57      0.57      0.57       438\n",
      "      middle       0.53      0.75      0.62       666\n",
      "upper_middle       0.37      0.12      0.19       251\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.39      0.29      0.28      1470\n",
      "weighted avg       0.49      0.53      0.48      1470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after hyperparameter tuning, accuracy still at 53%. <br>\n",
    "The f1 scores tell us that the model struggles with outlier classes (low, upper_middle, high) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Red Wine </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = red_wine_trans.drop(['quality', 'type', 'quality_label'], axis = 1)\n",
    "y_red = red_wine_trans['quality_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train | Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_red, y_red, test_size=0.3, random_state=101)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# Default uses L2 regularisation with C = 1.\n",
    "# multi_class = \"ovr\": binary classification multiple times, and choose label with highest hypothesis / probability. \n",
    "\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "log_model.fit(scaled_X_train, y_train)\n",
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         5\n",
      "         low       0.33      0.04      0.07        24\n",
      "lower_middle       0.68      0.75      0.71       208\n",
      "      middle       0.50      0.58      0.54       180\n",
      "upper_middle       0.46      0.27      0.34        63\n",
      "\n",
      "    accuracy                           0.58       480\n",
      "   macro avg       0.39      0.33      0.33       480\n",
      "weighted avg       0.56      0.58      0.56       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of 58%. <br>\n",
    "Macro f1 score average = 33%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> GridSearchCV to find optimal hyper parameters </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base log reg model\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(0.1,100,10)\n",
    "\n",
    "grid_model = GridSearchCV(log_model,param_grid={'C':C,'penalty':penalty}, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(scaled_X_train, y_train)\n",
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58125"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig, ax = plt.subplots(figsize=(5, 5))\\nplot_confusion_matrix(grid_model,scaled_X_test,y_test, ax = ax)\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot_confusion_matrix(grid_model,scaled_X_test,y_test, ax = ax)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         5\n",
      "         low       0.00      0.00      0.00        24\n",
      "lower_middle       0.67      0.77      0.72       208\n",
      "      middle       0.50      0.58      0.54       180\n",
      "upper_middle       0.42      0.21      0.28        63\n",
      "\n",
      "    accuracy                           0.58       480\n",
      "   macro avg       0.32      0.31      0.31       480\n",
      "weighted avg       0.53      0.58      0.55       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of 58%. Macro avg f1 score of 33% <br>\n",
    "Tuning of hyperparameters achieves no improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression With Smote  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> White Wine </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Split the data into training and test data first, and also scale, before doing over/under-sampling </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train | Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_white, y_white, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle          1532\n",
       "lower_middle    1019\n",
       "upper_middle     629\n",
       "high             125\n",
       "low              123\n",
       "Name: quality_label, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_strategy_white = {'middle': 1000, 'lower_middle': 1000, 'upper_middle': 629, 'low': 123, 'high': 125}\n",
    "over_strategy_white = {'middle': 1000, 'lower_middle': 1000, 'upper_middle': 800, 'low': 400, 'high': 400}\n",
    "\n",
    "under_white = RandomUnderSampler(sampling_strategy = under_strategy_white)\n",
    "over_white = SMOTE (sampling_strategy = over_strategy_white)\n",
    "\n",
    "scaled_X_train, y_train = under_white.fit_resample(scaled_X_train, y_train)\n",
    "scaled_X_train, y_train = over_white.fit_resample(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lower_middle    1000\n",
       "middle          1000\n",
       "upper_middle     800\n",
       "high             400\n",
       "low              400\n",
       "Name: quality_label, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# Default uses L2 regularisation with C = 1.\n",
    "# multi_class = \"ovr\": binary classification multiple times, and choose label with highest hypothesis / probability. \n",
    "\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "log_model.fit(scaled_X_train, y_train)\n",
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4673469387755102"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.22      0.09      0.13        55\n",
      "         low       0.23      0.37      0.29        60\n",
      "lower_middle       0.50      0.67      0.57       438\n",
      "      middle       0.58      0.33      0.42       666\n",
      "upper_middle       0.38      0.58      0.46       251\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.38      0.41      0.37      1470\n",
      "weighted avg       0.50      0.47      0.46      1470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tune hyperparameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base log reg model\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(0.01,30,20)\n",
    "\n",
    "grid_model = GridSearchCV(log_model,param_grid={'C':C,'penalty':penalty}, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=5000, multi_class='ovr',\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.00000000e-02, 1.58842105e+00, 3.16684211e+00, 4.74526316e+00,\n",
       "       6.32368421e+00, 7.90210526e+00, 9.48052632e+00, 1.10589474e+01,\n",
       "       1.26373684e+01, 1.42157895e+01, 1.57942105e+01, 1.73726316e+01,\n",
       "       1.89510526e+01, 2.05294737e+01, 2.21078947e+01, 2.36863158e+01,\n",
       "       2.52647368e+01, 2.68431579e+01, 2.84215789e+01, 3.00000000e+01]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 17.37263157894737, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.21      0.09      0.13        55\n",
      "         low       0.23      0.35      0.27        60\n",
      "lower_middle       0.50      0.67      0.57       438\n",
      "      middle       0.59      0.33      0.42       666\n",
      "upper_middle       0.38      0.58      0.46       251\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.38      0.40      0.37      1470\n",
      "weighted avg       0.50      0.47      0.46      1470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with SMOTE - White wine <br> <br>\n",
    "\n",
    "accuracy: 46% <br>\n",
    "f1 score macro avg: 37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression With Smote  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Red Wine </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Split the data into training and test data first, and also scale, before doing over/under-sampling </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train | Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_red, y_red, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lower_middle    473\n",
       "middle          458\n",
       "upper_middle    136\n",
       "low              39\n",
       "high             13\n",
       "Name: quality_label, dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_strategy_red = {'middle': 400, 'lower_middle': 400, 'upper_middle': 136, 'low': 39, 'high': 13}\n",
    "over_strategy_red = {'middle': 400, 'lower_middle': 400, 'upper_middle': 300, 'low': 100, 'high': 100}\n",
    "\n",
    "under_red = RandomUnderSampler(sampling_strategy = under_strategy_red)\n",
    "over_red = SMOTE (sampling_strategy = over_strategy_red)\n",
    "\n",
    "scaled_X_train, y_train = under_red.fit_resample(scaled_X_train, y_train)\n",
    "scaled_X_train, y_train = over_red.fit_resample(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lower_middle    400\n",
       "middle          400\n",
       "upper_middle    300\n",
       "high            100\n",
       "low             100\n",
       "Name: quality_label, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# Default uses L2 regularisation with C = 1.\n",
    "# multi_class = \"ovr\": binary classification multiple times, and choose label with highest hypothesis / probability. \n",
    "\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "log_model.fit(scaled_X_train, y_train)\n",
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5229166666666667"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         5\n",
      "         low       0.25      0.12      0.17        24\n",
      "lower_middle       0.69      0.70      0.70       208\n",
      "      middle       0.47      0.34      0.40       180\n",
      "upper_middle       0.34      0.63      0.45        63\n",
      "\n",
      "    accuracy                           0.52       480\n",
      "   macro avg       0.35      0.36      0.34       480\n",
      "weighted avg       0.53      0.52      0.52       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tune hyperparameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base log reg model\n",
    "log_model = LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(0.01,30,20)\n",
    "\n",
    "grid_model = GridSearchCV(log_model,param_grid={'C':C,'penalty':penalty}, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=5000, multi_class='ovr',\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.00000000e-02, 1.58842105e+00, 3.16684211e+00, 4.74526316e+00,\n",
       "       6.32368421e+00, 7.90210526e+00, 9.48052632e+00, 1.10589474e+01,\n",
       "       1.26373684e+01, 1.42157895e+01, 1.57942105e+01, 1.73726316e+01,\n",
       "       1.89510526e+01, 2.05294737e+01, 2.21078947e+01, 2.36863158e+01,\n",
       "       2.52647368e+01, 2.68431579e+01, 2.84215789e+01, 3.00000000e+01]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.745263157894737, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5229166666666667"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         5\n",
      "         low       0.25      0.12      0.17        24\n",
      "lower_middle       0.69      0.69      0.69       208\n",
      "      middle       0.48      0.36      0.41       180\n",
      "upper_middle       0.35      0.63      0.45        63\n",
      "\n",
      "    accuracy                           0.52       480\n",
      "   macro avg       0.35      0.36      0.34       480\n",
      "weighted avg       0.54      0.52      0.52       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with SMOTE â€“ red wine: <br>\n",
    "\n",
    "accuracy: 52% <br>\n",
    "f1 macro avg: 34%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
